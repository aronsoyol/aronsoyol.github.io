---
layout: post
title: "关于熵"
date: "2018-05-22 11:17:04 +0900"
---

## 熵

平均*信息量* 或 *信息量*的数学期望

## 信息量

*概率*的导数取log（一般以2位底）

## 概率的计算过程

下面是一个简单的语料库（corpus）,

```AAABB```

根据语料库计算字母的*概率*。

字母A的概率是$\frac{3}{5}$

字母B的概率是$\frac{2}{5}$

## 计算信息量的过程

字母A的*信息量*是$\log_2\{\frac{2}{5}^{-1}\} = -\log_2\{\frac{2}{5}\}$

字母B的*信息量*是$\log_2\{\frac{3}{5}^{-1}\} = -\log_2\{\frac{3}{5}\}$


## 计算熵的过程

有3个A，2个B,所以

$$\frac{3}{5}\times-\log_2\{\frac{3}{5}\} + \frac{3}{5}\times-\log_2\{\frac{3}{5}\} + \frac{3}{5}\times-\log_2\{\frac{3}{5}\} + \frac{2}{5}\times-\log_2\{\frac{2}{5}\}+ \frac{2}{5}\times-\log_2\{\frac{2}{5}\} \
= 1.6525187082781074$$

以下是python的计算结果
```
# e为低
>>> float(2/5)*- math.log(float(2)/5) * 2 - float(3/5)* math.log(float(3)/5) * 3
1.6525187082781074

# 2为低
>>> float(2/5)*- math.log2(float(2)/5) * 2 - float(3/5)* math.log2(float(3)/5) * 3
2.384080545409061
```

## 汉字的信息量的简单的计算

假设汉字有5000个，每个字的出现概率一样
汉字每个字的概率是
$$p=\frac{1}{5000}$$

每个汉字的信息量是

$$-log_2(p)= 12.287712379549449$$

以2为底的信息量的单位就是我们俗称的bit,也就是说表示一个汉字需要12.287712379549449个bit。

## 蒙文的信息量

假设有256个字母（U1800 ~ U18FF）

每个蒙文字母的概率是
$$p=\frac{1}{256} = 0.00390625$$

每个蒙文字母的信息量是

$$-log_2(p)= 8.0$$

熵是信息量的平均值，因为我在上面的举例中假设每个字母出现概率相同所以在这里 熵=信息量。
同样内容的汉文书比英文书薄，是因为汉字的信息量大，汉字的字母多所以信息量大。
